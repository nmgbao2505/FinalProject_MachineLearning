# Report
## 1. Giao diện và chức năng hoạt động

Người dùng sẽ nhập yêu cầu vào promt, sau đó ấn nút "Tạo code". Website sẽ phát sinh mã nguồn tương ứng với yêu cầu của người dùng. Ngoài ra, người dùng còn có thể điền tên file vào ô đầu tiên, hệ thống sẽ tạo một file chứa mã nguồn được phát sinh sau khi hoàn thành.

![](./code_generator/image-4.png)

Và đây là kết quả sau khi tạo code

![](./code_generator/image-3.png)

Kết quả khi chạy thử code trên trình biên dịch

![](./code_generator/image-5.png)

Thêm vào đó, website còn có khả năng hỗ trợ lập trình, phân tích các file dữ liệu csv của người dùng. Khi muốn lập trình tương tác với file csv, người dùng chọn "Browse files", chọn file tương ứng. Sau đó nhập yêu cầu mong muốn và chọn "Tạo code".

![](./code_generator/image-6.png)

Kết quả sau khi tạo code

![](./code_generator/image-7.png)
    
Kết quả khi chạy thử code trên trình biên dịch

![](./code_generator/image-8.png)
    
Sau khi hoàn thành, các file chứa những mã nguồn vừa được phát sinh sẽ được lưu trữ trong thư mục "codes".

![](./code_generator/image-10.png)
## 2. Kiến trúc mô hình:
Chương trình sử dụng Gemini API để phát sinh mã code theo yêu cầu người dùng. Chương trình hoạt động với cơ chế sau: 
        - Nhận và đọc yêu cầu người dùng giao diện streamlit.
        - Gửi yêu cầu và các tham số đến API Gemini.
        - Nhận kết quả và hiển thị cho người dùng.

Gemini (Google Bard) là một chatbot trí tuệ nhân tạo được phát triển bởi Google AI, ựa trên mô hình ngôn ngữ lớn. Nó được xây dựng dựa trên kiến trúc mạng nơ-ron nhân tạo Transformer, kiến trúc này là tiêu chuẩn cho các mô hình ngôn ngữ và được sử dụng trong nhiều ứng dụng khác nhau, bao gồm dịch máy, tóm tắt văn bản, và trả lời câu hỏi.

![](./code_generator/archi.png)

1. Layer đầu vào:
    - Nhận dữ liệu đầu vào là các đoạn văn gồm yêu cầu của người dùng và dữ liệu từ file csv nếu có từ API Gemini.
    - Sử dụng kỹ thuật word embedding để chuyển đổi văn bản thành dạng vector, trong đó mỗi từ được biểu diễn bởi một vector tương ứng.
    - Layer Positional Encoding: Thêm thông tin về vị trí của các từ trong câu để mô hình có thể hiểu được trật tự của các từ và ngữ cảnh của câu.

2. Encoder layer:
    - Gồm nhiều Encoder Layer được xếp chồng lên nhau, mỗi layer có thể lặp lại nhiều lần.
    - Mỗi Encoder Layer bao gồm:
        - Self-attention: Cho phép mô hình tập trung vào các phần quan trọng của văn bản đầu vào bằng cách tính toán mức độ liên quan giữa các từ trong câu.
        - Multi-head attention: Sử dụng nhiều head attention để mô hình có thể tập trung vào nhiều khía cạnh khác nhau của văn bản.
        - Feed-forward network: Xử lý thông tin chi tiết hơn bằng cách áp dụng một mạng nơ-ron feed-forward lên vector biểu diễn của văn bản.
        - Residual connection: Kết nối vector đầu vào của layer với vector đầu ra của layer để giúp mô hình học được tốt hơn.
        - Layer Normalization: Giúp ổn định quá trình học tập bằng cách chuẩn hóa vector đầu ra của layer.
3. Decoder layer:
    - Tương tự như Encoder layer, nhưng thay vì tạo ra vector biểu diễn cho văn bản, nó tạo ra văn bản mới.
    - Gồm nhiều Decoder Layer được xếp chồng lên nhau, mỗi layer có thể lặp lại nhiều lần.
    - Mỗi Decoder Layer bao gồm:
        - Masked self-attention: Tương tự như self-attention trong Encoder, nhưng chỉ tập trung vào các phần văn bản đã được tạo ra trước đó để tránh lặp lại.
        - Encoder-decoder attention: Cho phép mô hình tập trung vào vector biểu diễn được tạo ra bởi Encoder để đảm bảo văn bản được tạo ra có liên quan đến văn bản đầu vào.
        - Các thành phần còn lại giống như Encoder layer nhưng dùng để điều chỉnh kết quả đầu ra của mô hình.
4. Layer đầu ra:
    - Chuyển đổi vector biểu diễn được tạo ra bởi Decoder thành văn bản hoặc lời nói.
    - Sử dụng kỹ thuật word embedding ngược lại để ánh xạ vector biểu diễn của mỗi từ sang từ tương ứng trong ngôn ngữ tự nhiên.
5. Layer bổ sung:
    - Layer Beam Search: Giúp mô hình tìm ra chuỗi văn bản có khả năng cao nhất thay vì chỉ tạo ra một chuỗi duy nhất.
    - Layer Length Penalty: Giúp mô hình tạo ra văn bản có độ dài phù hợp với ngữ cảnh.
    - Layer Temperature: Điều chỉnh mức độ sáng tạo của văn bản được tạo ra.

![](./code_generator/archi2.jfif)

## 3. Hạn chế:

- Do chương trình phải sử dụng API của Gemini nên sẽ bị một hạn chế lớn đó là chỉ có thể nhập vào 10000 ký tự, bao gồm cả dữ liệu trong file csv.

- Ngoài ra, đối với các yêu cầu lập trình phức tạp, chương trình sẽ không thế đưa ra mã nguồn hoàn chỉnh hoặc có độ chính xác không đảm bảo.